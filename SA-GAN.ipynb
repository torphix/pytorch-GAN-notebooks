{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from typing import Dict, Any\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load celebA dataset\n",
    "def get_dataloader(batch_size, shuffle, n_workers, image_size):\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize(image_size),\n",
    "            torchvision.transforms.CenterCrop(image_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "    dataset = torchvision.datasets.CelebA(\n",
    "        root=\"./data\", transform=transform, download=True\n",
    "    )\n",
    "    def lenx():\n",
    "        return 100\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=n_workers\n",
    "    )\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionConv(nn.Module):\n",
    "    def __init__(self, in_d, downscale_factor=8):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Downscale factor is suggested in the paper to reduce memory consumption\n",
    "        they use 8, but 4 or 2 can be used with enough gpu memory\n",
    "        \"\"\"\n",
    "        self.downscale_factor = downscale_factor\n",
    "        self.k_conv = nn.Conv2d(in_d, in_d // self.downscale_factor, 1, 1, 0)\n",
    "        self.q_conv = nn.Conv2d(in_d, in_d // self.downscale_factor, 1, 1, 0)\n",
    "        self.v_conv = nn.Conv2d(in_d, in_d, 1, 1, 0)\n",
    "        # gamma is a learnable parameter (used in original paper)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.out_conv = nn.Conv2d(in_d, in_d, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, in_d, h, w)\n",
    "        \"\"\"\n",
    "        batch_size, in_d, h, w = x.shape\n",
    "        # Embed input and reshape for matrix multiplication\n",
    "        k = self.k_conv(x).view(batch_size, -1, h * w)\n",
    "        q = self.q_conv(x).view(batch_size, -1, h * w)\n",
    "        v = self.v_conv(x).view(batch_size, -1, h * w)\n",
    "        # (batch_size, h * w, h * w)\n",
    "        attn = torch.bmm(k.transpose(-2, -1), q)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        # (batch_size, in_d, h * w)\n",
    "        out = torch.bmm(v, attn.transpose(-2, -1))\n",
    "        out = out.view(batch_size, in_d, h, w)\n",
    "        out = self.out_conv(out)\n",
    "        # Add residual connection and scale by learnable parameter gamma\n",
    "        out = self.gamma * out + x\n",
    "        return out, attn\n",
    "\n",
    "\n",
    "# Generator, DC-GAN with self attention\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, target_output_size=128, emb_dim=1024):\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dim, emb_dim, 4),\n",
    "            nn.BatchNorm2d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        n_layers = int(np.log2(target_output_size))\n",
    "        for _ in range(n_layers - 3):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.utils.spectral_norm(\n",
    "                        nn.ConvTranspose2d(\n",
    "                            emb_dim,\n",
    "                            emb_dim // 2 if emb_dim // 2 >= 64 else emb_dim,\n",
    "                            kernel_size=4,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                        )\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(emb_dim // 2 if emb_dim // 2 >= 64 else emb_dim),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "            # Don't shrink emb_dim below too low\n",
    "            if emb_dim // 2 >= 64:\n",
    "                emb_dim = emb_dim // 2\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        # Self attention sandwhiches the penultimate layer\n",
    "        self.self_attn_1 = SelfAttentionConv(emb_dim)\n",
    "        self.self_attn_2 = SelfAttentionConv(emb_dim)\n",
    "        self.penultimate_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(emb_dim, emb_dim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out_layer = nn.Sequential(\n",
    "            nn.ConvTranspose2d(emb_dim, 3, 4, 2, 1), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.in_layer(noise)\n",
    "        # Main layers\n",
    "        out = self.layers(out)\n",
    "        # Attention layers\n",
    "        out, attn1 = self.self_attn_1(out)\n",
    "        out = self.penultimate_layer(out)\n",
    "        out, attn2 = self.self_attn_2(out)\n",
    "        # Out layers\n",
    "        out = self.out_layer(out)\n",
    "        return out, attn1, attn2\n",
    "\n",
    "\n",
    "# # Discriminator, adopts the PatchGAN architecture ie: output is a receptive field of n x n\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_d=3, emb_dim=512, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_d, emb_dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(emb_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.utils.spectral_norm(\n",
    "                        nn.Conv2d(\n",
    "                            emb_dim,\n",
    "                            emb_dim // 2 if emb_dim // 2 >= 64 else emb_dim,\n",
    "                            kernel_size=4,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                        )\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(emb_dim // 2 if emb_dim // 2 >= 64 else emb_dim),\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "            )\n",
    "            # Don't shrink emb_dim below too low\n",
    "            if emb_dim // 2 >= 64:\n",
    "                emb_dim = emb_dim // 2\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        # Self attention sandwhiches the penultimate layer\n",
    "        self.self_attn_1 = SelfAttentionConv(emb_dim)\n",
    "        self.self_attn_2 = SelfAttentionConv(emb_dim)\n",
    "        self.penultimate_layer = nn.Sequential(\n",
    "            nn.Conv2d(emb_dim, emb_dim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(emb_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out_layer = nn.Conv2d(emb_dim, 1, 4)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.in_layer(noise)\n",
    "        # Main layers\n",
    "        out = self.layers(out)\n",
    "        # Attention layers\n",
    "        out, attn1 = self.self_attn_1(out)\n",
    "        out = self.penultimate_layer(out)\n",
    "        out, attn2 = self.self_attn_2(out)\n",
    "        # Out layers\n",
    "        out = self.out_layer(out)\n",
    "        return out, attn1, attn2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_ckpt_steps: int,\n",
    "        n_log_steps: int,\n",
    "        epochs: int,\n",
    "        # Data parameters\n",
    "        batch_size: int,\n",
    "        # Optimiser parameters\n",
    "        g_lr: float,\n",
    "        d_lr: float,\n",
    "        # Model parameters\n",
    "        noise_d: int,\n",
    "        emb_d: int,\n",
    "        output_size: int,\n",
    "        flush_prev_logs: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        n_ckpt_steps: Saves a checkpoint every n_ckpt_steps\n",
    "        n_log_steps: Logs every n_log_steps\n",
    "        epochs: Number of epochs to train for\n",
    "        batch_size: Batch size\n",
    "        lr: Learning rate\n",
    "        noise_d: Noise dimension\n",
    "        emb_d: Embedding dimension\n",
    "        output_size: Output size ie: height and width of the image\n",
    "        flush_prev_logs: Flushes previous logs and checkpoints\n",
    "        \"\"\"\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        # Initialize models\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.generator = Generator(\n",
    "            noise_dim=noise_d,\n",
    "            emb_dim=emb_d,\n",
    "            target_output_size=output_size,\n",
    "        ).to(self.device)\n",
    "        self.discriminator = Discriminator().to(self.device)\n",
    "        # Initialize optimisers\n",
    "        self.optim_G = torch.optim.Adam(\n",
    "            self.generator.parameters(),\n",
    "            lr=g_lr,\n",
    "        )\n",
    "        self.optim_D = torch.optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=d_lr,\n",
    "        )\n",
    "        self.train_dataloader = get_dataloader(batch_size, True, 4, output_size)\n",
    "        # Hyperparameters\n",
    "        self.n_log_steps = n_log_steps\n",
    "        self.n_ckpt_steps = n_ckpt_steps\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.noise_d = noise_d\n",
    "        # Init globals & Metrics\n",
    "        self.global_step = 0\n",
    "        self.inception = InceptionScore(normalize=True)\n",
    "        self.fid = FrechetInceptionDistance()\n",
    "        self.metrics, self.g_losses, self.d_losses = [], [], []\n",
    "        # Reset logs\n",
    "        if flush_prev_logs:\n",
    "            shutil.rmtree(\"results\", ignore_errors=True)\n",
    "        # Create log directory\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        self.log_dir = f'results/logs/train-run-{len(os.listdir(\"results/logs\")) + 1}'\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        os.makedirs(f\"{self.log_dir}/images\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.log_dir}/metrics\", exist_ok=True)\n",
    "        os.makedirs(f\"{self.log_dir}/checkpoints\", exist_ok=True)\n",
    "        print(f\"Logging to {self.log_dir}\")\n",
    "\n",
    "    def to_device(self, *args):\n",
    "        return [arg.to(self.device) for arg in args]\n",
    "\n",
    "    def run(self):\n",
    "        for e in range(self.epochs):\n",
    "            self.train_iter(e)\n",
    "        # Save final model\n",
    "        torch.save(self.generator.state_dict(), f\"{self.log_dir}/generator.pt\")\n",
    "        # Save losses\n",
    "        torch.save(self.g_losses, f\"{self.log_dir}/g_losses.pt\")\n",
    "        torch.save(self.d_losses, f\"{self.log_dir}/d_losses.pt\")\n",
    "\n",
    "    def train_iter(self, epoch: int):\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        # Train on a batch of images\n",
    "        for i, (real_img, tags) in enumerate(\n",
    "            tqdm(self.train_dataloader, desc=f\"Epoch: {epoch}\", leave=False)\n",
    "        ):\n",
    "            real_img, tags = real_img.to(self.device), tags.to(self.device)\n",
    "            # Train the discriminator\n",
    "            self.optim_D.zero_grad()\n",
    "            noise = torch.randn((self.batch_size, 100, 1, 1)).to(self.device)\n",
    "            fake_image, _, _ = self.generator(noise)\n",
    "            loss_D = self.compute_discriminator_loss(real_img, fake_image)\n",
    "            loss_D.backward()\n",
    "            self.optim_D.step()\n",
    "            # Train the generators\n",
    "            self.optim_G.zero_grad()\n",
    "            loss_G = self.compute_generator_loss()\n",
    "            loss_G.backward()\n",
    "            self.optim_G.step()\n",
    "            # Log the losses & Metrics\n",
    "            if self.global_step % self.n_log_steps == 0:\n",
    "                self.g_losses.append(loss_G.item())\n",
    "                self.d_losses.append(loss_D.item())\n",
    "                self.log_image(real_img, f\"{self.global_step}_real_image.png\")\n",
    "                self.log_image(\n",
    "                    self.generator(noise)[0], f\"{self.global_step}_fake_image.png\"\n",
    "                )\n",
    "                # Compute inception score\n",
    "                self.inception.update(self.generator(noise))\n",
    "                # Compute FID\n",
    "                self.fid.update(self.generator(noise), False)\n",
    "                self.fid.update(real_img, True)\n",
    "                # Compute discriminator accuracy\n",
    "                real_pred_D, _, _ = self.discriminator(real_img)\n",
    "                fake_pred_D, _, _ = self.discriminator(fake_image)\n",
    "                real_acc = (real_pred_D > 0).float().mean()\n",
    "                fake_acc = (fake_pred_D < 0).float().mean()\n",
    "                # Log the metrics\n",
    "                self.log_metrics(\n",
    "                    {\n",
    "                        \"Generator Loss\": loss_G.item(),\n",
    "                        \"Discriminator Loss\": loss_D.item(),\n",
    "                        \"Inception Score\": self.inception.compute(),\n",
    "                        \"FID\": self.fid.compute(),\n",
    "                        \"Real Accuracy\": real_acc.item(),\n",
    "                        \"Fake Accuracy\": fake_acc.item(),\n",
    "                    }\n",
    "                )\n",
    "            # Increment the global step\n",
    "            self.global_step += 1\n",
    "            # Save a checkpoint\n",
    "            if self.global_step % self.n_ckpt_steps == 0:\n",
    "                self.save_checkpoint()\n",
    "\n",
    "    def compute_generator_loss(self) -> torch.Tensor:\n",
    "        noise_x = torch.randn(self.batch_size, self.noise_d, 1, 1).to(self.device)\n",
    "        fake_image, _, _ = self.generator(noise_x)\n",
    "        fake_pred_D, _, _ = self.discriminator(fake_image)\n",
    "        # Hinge loss as specified in the paper\n",
    "        loss_G = -fake_pred_D.mean()\n",
    "        return loss_G\n",
    "\n",
    "    def compute_discriminator_loss(\n",
    "        self,\n",
    "        real_img: torch.Tensor,\n",
    "        generated_img: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        real_pred_D, _, _ = self.discriminator(real_img)\n",
    "        fake_pred_D, _, _ = self.discriminator(generated_img)\n",
    "        # Hinge loss as specified in the paper\n",
    "        loss_D = F.relu(1 - real_pred_D).mean() + F.relu(1 + fake_pred_D).mean()\n",
    "        return loss_D\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"generator\": self.generator.state_dict(),\n",
    "                \"discriminator\": self.discriminator.state_dict(),\n",
    "                \"optim_G\": self.optim_G.state_dict(),\n",
    "                \"optim_D\": self.optim_D.state_dict(),\n",
    "            },\n",
    "            f\"{self.log_dir}/checkpoints/step-{self.global_step}.pt\",\n",
    "        )\n",
    "\n",
    "    def load_checkpoint(self, path: str):\n",
    "        state_dict = torch.load(path)\n",
    "        self.generator.load_state_dict(state_dict[\"generator\"])\n",
    "        self.discriminator.load_state_dict(state_dict[\"discriminator\"])\n",
    "        self.optim_G.load_state_dict(state_dict[\"optim_G\"])\n",
    "        self.optim_D.load_state_dict(state_dict[\"optim_D\"])\n",
    "\n",
    "    def log_image(self, img: torch.Tensor, name: str):\n",
    "        print(img)\n",
    "        torchvision.utils.save_image(\n",
    "            img,\n",
    "            f\"{self.log_dir}/images/{name}\",\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        )\n",
    "\n",
    "    def log_metrics(self, metrics: Dict[str, Any]):\n",
    "        self.metrics.append(metrics)\n",
    "        with open(f\"{self.log_dir}/metrics/metrics.json\", \"w\") as f:\n",
    "            json.dump(self.metrics, f, indent=4)\n",
    "        self.metrics = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Logging to results/logs/train-run-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/2544 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0353,  0.0510,  0.0667,  ..., -0.3882, -0.4039, -0.4275],\n",
      "          [ 0.0980,  0.1137,  0.1294,  ..., -0.4824, -0.4980, -0.5137],\n",
      "          [ 0.1294,  0.1451,  0.1529,  ..., -0.6078, -0.6235, -0.6392],\n",
      "          ...,\n",
      "          [ 0.3333,  0.1922, -0.4196,  ...,  0.2549,  0.2863,  0.3804],\n",
      "          [ 0.2941,  0.1529, -0.3176,  ...,  0.3569,  0.3647,  0.4275],\n",
      "          [ 0.1137, -0.1294, -0.4353,  ...,  0.4353,  0.5216,  0.5608]],\n",
      "\n",
      "         [[ 0.1216,  0.1373,  0.1608,  ..., -0.2627, -0.2627, -0.2706],\n",
      "          [ 0.1216,  0.1373,  0.1529,  ..., -0.3255, -0.3333, -0.3333],\n",
      "          [ 0.1216,  0.1373,  0.1451,  ..., -0.3961, -0.3961, -0.4039],\n",
      "          ...,\n",
      "          [-0.4431, -0.2863, -0.3725,  ...,  0.0745,  0.0980,  0.2157],\n",
      "          [-0.3882, -0.2235, -0.3333,  ...,  0.1216,  0.0980,  0.1843],\n",
      "          [-0.2235, -0.3412, -0.4745,  ...,  0.1529,  0.2314,  0.3412]],\n",
      "\n",
      "         [[ 0.3804,  0.3961,  0.3961,  ..., -0.0667, -0.0667, -0.0588],\n",
      "          [ 0.3569,  0.3647,  0.3725,  ..., -0.0980, -0.0980, -0.0980],\n",
      "          [ 0.3176,  0.3176,  0.3176,  ..., -0.1059, -0.1059, -0.1216],\n",
      "          ...,\n",
      "          [-0.2784,  0.0275,  0.2863,  ..., -0.0745, -0.0824,  0.0431],\n",
      "          [-0.1765,  0.1608,  0.2784,  ..., -0.0510, -0.0588,  0.0353],\n",
      "          [ 0.0588,  0.0745,  0.0902,  ..., -0.0353,  0.0667,  0.2235]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2157,  0.1922,  0.1686,  ..., -0.2549, -0.2627, -0.2706],\n",
      "          [ 0.2314,  0.2235,  0.1843,  ..., -0.2627, -0.2549, -0.2392],\n",
      "          [ 0.2471,  0.2157,  0.1843,  ..., -0.2627, -0.2627, -0.2392],\n",
      "          ...,\n",
      "          [ 0.2941,  0.3569,  0.5843,  ..., -0.1765, -0.2549, -0.2627],\n",
      "          [ 0.2471,  0.3333,  0.0588,  ...,  0.1373, -0.2157, -0.2549],\n",
      "          [-0.3255, -0.4275, -0.4824,  ...,  0.5843,  0.1686, -0.1686]],\n",
      "\n",
      "         [[ 0.0039, -0.0196, -0.0431,  ..., -0.5529, -0.5608, -0.5529],\n",
      "          [ 0.0196,  0.0118, -0.0275,  ..., -0.5608, -0.5529, -0.5608],\n",
      "          [ 0.0353,  0.0039, -0.0275,  ..., -0.5608, -0.5608, -0.5686],\n",
      "          ...,\n",
      "          [ 0.0980,  0.2000,  0.4431,  ..., -0.1765, -0.2471, -0.2627],\n",
      "          [ 0.0980,  0.2078, -0.0196,  ...,  0.1451, -0.2078, -0.2627],\n",
      "          [-0.3725, -0.4667, -0.5137,  ...,  0.5843,  0.1843, -0.1686]],\n",
      "\n",
      "         [[-0.2235, -0.2471, -0.2706,  ..., -0.6235, -0.6314, -0.6235],\n",
      "          [-0.2078, -0.2157, -0.2549,  ..., -0.6314, -0.6235, -0.6314],\n",
      "          [-0.1922, -0.2235, -0.2549,  ..., -0.6314, -0.6314, -0.6392],\n",
      "          ...,\n",
      "          [ 0.1216,  0.2235,  0.4745,  ..., -0.1608, -0.2314, -0.2235],\n",
      "          [ 0.1294,  0.2314, -0.0118,  ...,  0.1529, -0.1843, -0.2549],\n",
      "          [-0.3725, -0.4667, -0.5216,  ...,  0.6000,  0.2000, -0.1608]]],\n",
      "\n",
      "\n",
      "        [[[-0.7490, -0.7176, -0.7333,  ..., -0.7098, -0.7098, -0.7020],\n",
      "          [-0.7412, -0.7098, -0.7255,  ..., -0.7020, -0.7020, -0.6941],\n",
      "          [-0.7333, -0.7176, -0.7255,  ..., -0.6784, -0.6863, -0.6706],\n",
      "          ...,\n",
      "          [-0.6941, -0.6863, -0.7098,  ..., -0.6941, -0.6784, -0.6863],\n",
      "          [-0.6941, -0.6863, -0.7020,  ..., -0.6941, -0.6941, -0.6392],\n",
      "          [-0.6784, -0.6784, -0.7020,  ..., -0.7020, -0.6784, -0.5373]],\n",
      "\n",
      "         [[-0.7490, -0.7176, -0.7333,  ..., -0.7020, -0.7098, -0.7020],\n",
      "          [-0.7412, -0.7098, -0.7255,  ..., -0.6941, -0.7020, -0.6863],\n",
      "          [-0.7333, -0.7176, -0.7255,  ..., -0.6706, -0.6784, -0.6627],\n",
      "          ...,\n",
      "          [-0.6941, -0.6863, -0.7098,  ..., -0.7176, -0.7020, -0.7020],\n",
      "          [-0.6941, -0.6863, -0.7020,  ..., -0.7098, -0.7020, -0.6392],\n",
      "          [-0.6784, -0.6784, -0.7020,  ..., -0.7020, -0.6784, -0.5373]],\n",
      "\n",
      "         [[-0.7647, -0.7333, -0.7490,  ..., -0.7255, -0.7333, -0.7333],\n",
      "          [-0.7569, -0.7255, -0.7412,  ..., -0.7333, -0.7412, -0.7333],\n",
      "          [-0.7490, -0.7333, -0.7412,  ..., -0.7176, -0.7255, -0.7176],\n",
      "          ...,\n",
      "          [-0.7725, -0.7647, -0.7725,  ..., -0.7490, -0.7412, -0.7490],\n",
      "          [-0.7725, -0.7569, -0.7647,  ..., -0.7569, -0.7647, -0.7020],\n",
      "          [-0.7569, -0.7490, -0.7569,  ..., -0.7490, -0.7333, -0.6000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.6314, -0.6157, -0.5686,  ..., -0.6863, -0.6863, -0.6706],\n",
      "          [-0.6314, -0.6314, -0.6000,  ..., -0.6863, -0.6863, -0.6706],\n",
      "          [-0.6314, -0.6392, -0.6549,  ..., -0.6784, -0.6784, -0.6627],\n",
      "          ...,\n",
      "          [ 0.5137, -0.0118, -0.2157,  ...,  0.5765,  0.6784,  0.9686],\n",
      "          [ 0.0275, -0.6471, -0.1216,  ...,  0.6078,  0.7961,  0.9686],\n",
      "          [-0.5451, -0.7255, -0.4745,  ...,  0.6078,  0.8902,  0.9451]],\n",
      "\n",
      "         [[-0.6471, -0.6549, -0.6392,  ..., -0.7020, -0.7020, -0.6863],\n",
      "          [-0.6627, -0.6627, -0.6392,  ..., -0.7020, -0.7020, -0.6863],\n",
      "          [-0.6784, -0.6784, -0.6706,  ..., -0.6941, -0.6941, -0.6784],\n",
      "          ...,\n",
      "          [ 0.5373,  0.0039, -0.2392,  ..., -0.1059,  0.1765,  0.7412],\n",
      "          [ 0.0353, -0.6392, -0.1373,  ..., -0.0667,  0.3569,  0.8196],\n",
      "          [-0.5765, -0.7412, -0.5137,  ..., -0.0039,  0.5529,  0.8510]],\n",
      "\n",
      "         [[-0.6863, -0.6549, -0.6000,  ..., -0.6941, -0.6941, -0.6784],\n",
      "          [-0.6941, -0.6627, -0.6157,  ..., -0.6941, -0.6941, -0.6784],\n",
      "          [-0.7020, -0.6784, -0.6549,  ..., -0.6863, -0.6863, -0.6706],\n",
      "          ...,\n",
      "          [ 0.5294,  0.0118, -0.2549,  ..., -0.3255,  0.0745,  0.7647],\n",
      "          [ 0.0196, -0.6235, -0.1373,  ..., -0.2941,  0.2941,  0.8431],\n",
      "          [-0.5765, -0.7098, -0.4824,  ..., -0.2000,  0.5059,  0.8588]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8353,  0.8353,  0.8353,  ...,  0.7882,  0.7804,  0.7804],\n",
      "          [ 0.8353,  0.8353,  0.8353,  ...,  0.7882,  0.7804,  0.7882],\n",
      "          [ 0.8353,  0.8275,  0.8353,  ...,  0.7882,  0.7882,  0.7882],\n",
      "          ...,\n",
      "          [-0.3255, -0.2706, -0.3569,  ...,  0.7098,  0.7098,  0.7020],\n",
      "          [-0.3882, -0.3647, -0.4196,  ...,  0.7098,  0.7176,  0.7020],\n",
      "          [-0.4118, -0.3961, -0.4118,  ...,  0.7098,  0.7098,  0.7020]],\n",
      "\n",
      "         [[ 0.8588,  0.8588,  0.8588,  ...,  0.8118,  0.8039,  0.8039],\n",
      "          [ 0.8588,  0.8588,  0.8588,  ...,  0.8118,  0.8039,  0.8118],\n",
      "          [ 0.8588,  0.8510,  0.8588,  ...,  0.8118,  0.8118,  0.8118],\n",
      "          ...,\n",
      "          [-0.6000, -0.5373, -0.6314,  ...,  0.7412,  0.7412,  0.7333],\n",
      "          [-0.6471, -0.6314, -0.6863,  ...,  0.7255,  0.7255,  0.7255],\n",
      "          [-0.6784, -0.6706, -0.6941,  ...,  0.7255,  0.7255,  0.7255]],\n",
      "\n",
      "         [[ 0.9765,  0.9765,  0.9765,  ...,  0.9294,  0.9216,  0.9216],\n",
      "          [ 0.9765,  0.9765,  0.9765,  ...,  0.9294,  0.9216,  0.9294],\n",
      "          [ 0.9765,  0.9686,  0.9765,  ...,  0.9294,  0.9294,  0.9294],\n",
      "          ...,\n",
      "          [-0.7255, -0.6627, -0.7569,  ...,  0.8275,  0.8196,  0.8196],\n",
      "          [-0.7490, -0.7412, -0.8039,  ...,  0.8118,  0.8118,  0.8118],\n",
      "          [-0.7725, -0.7725, -0.8039,  ...,  0.8275,  0.8353,  0.8275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3255,  0.3020,  0.1922,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [ 0.3412,  0.3098,  0.2000,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [ 0.3333,  0.2941,  0.2000,  ..., -0.9843, -0.9843, -0.9922],\n",
      "          ...,\n",
      "          [-0.8667, -0.8667, -0.8745,  ..., -0.9451, -0.9529, -0.9294],\n",
      "          [-0.8745, -0.8824, -0.8824,  ..., -0.9373, -0.9137, -0.9137],\n",
      "          [-0.8902, -0.8824, -0.8824,  ..., -0.9373, -0.9216, -0.9451]],\n",
      "\n",
      "         [[ 0.3804,  0.3569,  0.2627,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [ 0.3961,  0.3725,  0.2706,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [ 0.3882,  0.3569,  0.2706,  ..., -0.9843, -0.9843, -0.9922],\n",
      "          ...,\n",
      "          [-0.8588, -0.8588, -0.8667,  ..., -0.9373, -0.9451, -0.9216],\n",
      "          [-0.8667, -0.8745, -0.8745,  ..., -0.9294, -0.9059, -0.9059],\n",
      "          [-0.8824, -0.8745, -0.8745,  ..., -0.9294, -0.9137, -0.9373]],\n",
      "\n",
      "         [[ 0.4667,  0.4667,  0.4039,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [ 0.4667,  0.4588,  0.4039,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [ 0.4431,  0.4431,  0.3961,  ..., -0.9843, -0.9843, -0.9922],\n",
      "          ...,\n",
      "          [-0.8431, -0.8431, -0.8510,  ..., -0.9216, -0.9294, -0.9059],\n",
      "          [-0.8510, -0.8588, -0.8588,  ..., -0.9137, -0.8902, -0.8902],\n",
      "          [-0.8667, -0.8588, -0.8588,  ..., -0.9137, -0.8980, -0.9216]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[-2.9021e-01, -1.7874e-01,  4.4707e-03,  ..., -4.3614e-01,\n",
      "           -2.8595e-01, -3.9394e-01],\n",
      "          [-4.9998e-01, -4.4435e-01, -9.3942e-01,  ...,  2.4254e-01,\n",
      "           -6.6332e-01, -6.7543e-01],\n",
      "          [-7.0866e-02, -8.3994e-01,  4.1033e-01,  ..., -7.5248e-01,\n",
      "            1.8147e-01, -5.1716e-01],\n",
      "          ...,\n",
      "          [-2.8502e-01, -9.5794e-02, -1.1470e-01,  ..., -5.9488e-02,\n",
      "           -5.1012e-01, -5.2421e-01],\n",
      "          [-3.8732e-02, -1.1320e-01,  7.4140e-01,  ..., -4.1354e-02,\n",
      "            3.6256e-01, -5.2657e-01],\n",
      "          [-1.7304e-01,  5.3277e-02, -3.5788e-01,  ..., -2.5911e-01,\n",
      "           -4.1989e-01, -1.9605e-01]],\n",
      "\n",
      "         [[ 3.2186e-01, -1.5536e-01,  5.3480e-01,  ...,  2.3595e-01,\n",
      "            5.5744e-01,  9.2333e-02],\n",
      "          [-4.1673e-01, -7.2673e-01, -6.2800e-01,  ..., -6.4598e-01,\n",
      "           -2.1968e-01, -2.6744e-01],\n",
      "          [ 5.2566e-01,  4.6003e-01, -3.6605e-02,  ...,  3.9646e-01,\n",
      "            3.0248e-01,  1.7933e-01],\n",
      "          ...,\n",
      "          [-2.4633e-01,  5.9655e-02,  5.9360e-01,  ..., -4.3410e-01,\n",
      "            4.1450e-01, -4.6568e-01],\n",
      "          [ 2.8514e-01, -6.4167e-02,  9.3983e-02,  ...,  3.8160e-01,\n",
      "            3.3997e-01,  4.4169e-01],\n",
      "          [-1.0466e-01, -7.5311e-01, -1.5361e-01,  ..., -7.7952e-01,\n",
      "           -1.4006e-01, -6.3734e-01]],\n",
      "\n",
      "         [[-1.1352e-01, -5.7371e-01,  3.0856e-01,  ...,  2.6290e-02,\n",
      "            2.7378e-01, -2.6332e-01],\n",
      "          [-1.5286e-01,  3.4662e-01, -2.4259e-01,  ...,  3.7470e-01,\n",
      "           -6.3715e-01, -5.2289e-01],\n",
      "          [ 1.0850e-01,  2.1031e-01,  2.5541e-01,  ...,  1.8700e-01,\n",
      "           -1.6094e-01, -6.7792e-01],\n",
      "          ...,\n",
      "          [-3.5195e-01,  7.0696e-01,  1.4207e-01,  ...,  7.1599e-02,\n",
      "           -4.6199e-01, -1.9692e-01],\n",
      "          [ 1.3647e-01, -4.0604e-01,  3.0451e-01,  ..., -6.1009e-01,\n",
      "           -1.9756e-01, -7.0605e-01],\n",
      "          [ 3.6145e-02,  6.0342e-02,  1.4509e-01,  ...,  6.7917e-02,\n",
      "            2.6175e-01, -1.0314e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2743e-01,  1.1330e-01, -2.5540e-01,  ..., -6.5590e-01,\n",
      "           -5.4657e-01, -3.3267e-01],\n",
      "          [-2.2723e-01,  2.3145e-01, -7.2338e-01,  ...,  8.6578e-02,\n",
      "           -7.4901e-01, -5.9857e-01],\n",
      "          [-1.4183e-01, -8.7745e-01,  5.1010e-01,  ..., -7.9777e-01,\n",
      "            4.7036e-01, -5.5195e-01],\n",
      "          ...,\n",
      "          [-3.4364e-01,  6.9021e-01, -2.1271e-01,  ..., -5.1179e-01,\n",
      "           -5.9063e-01, -6.7170e-01],\n",
      "          [-1.8501e-01, -4.2215e-01,  7.0201e-01,  ..., -5.4342e-01,\n",
      "            5.0273e-01, -6.9918e-01],\n",
      "          [ 2.3734e-01,  1.2631e-01, -1.3812e-01,  ...,  3.5034e-02,\n",
      "           -7.9862e-02, -3.0794e-01]],\n",
      "\n",
      "         [[ 4.0459e-01,  2.8596e-01,  7.1411e-01,  ...,  4.2453e-01,\n",
      "            2.8025e-01,  2.8140e-03],\n",
      "          [-2.2404e-01, -8.3684e-01, -1.5755e-01,  ..., -6.4985e-01,\n",
      "           -5.9212e-01, -5.4695e-01],\n",
      "          [ 2.4708e-01,  3.3876e-01,  3.6582e-01,  ...,  1.0565e-01,\n",
      "            2.2890e-01,  2.7563e-01],\n",
      "          ...,\n",
      "          [-1.4629e-01,  4.4520e-01,  6.1568e-01,  ..., -4.0532e-01,\n",
      "           -5.2748e-01, -1.3469e-01],\n",
      "          [ 1.1952e-01, -4.0163e-01,  4.1969e-01,  ...,  8.3624e-01,\n",
      "            7.4151e-02,  2.5749e-01],\n",
      "          [-2.8142e-01, -5.8490e-01,  1.9647e-01,  ..., -6.9350e-01,\n",
      "           -7.4351e-02, -6.9284e-01]],\n",
      "\n",
      "         [[-4.7407e-02, -5.3651e-01,  4.5468e-01,  ...,  7.5920e-02,\n",
      "            1.7176e-01, -4.6634e-01],\n",
      "          [-1.4677e-01,  3.6445e-01, -5.5471e-02,  ..., -5.4622e-03,\n",
      "           -5.3096e-01, -7.3031e-01],\n",
      "          [-1.0738e-01,  1.4188e-01,  4.5952e-01,  ...,  1.4407e-01,\n",
      "           -2.4419e-01, -5.8448e-01],\n",
      "          ...,\n",
      "          [-1.6515e-01,  8.0667e-01,  2.6444e-01,  ...,  2.3343e-01,\n",
      "           -2.6537e-01, -4.9626e-01],\n",
      "          [ 2.4791e-01, -2.9442e-01,  1.7624e-01,  ..., -3.7162e-01,\n",
      "            3.4059e-01, -5.1067e-01],\n",
      "          [-9.4477e-02, -2.1263e-01,  3.3620e-01,  ..., -1.0605e-01,\n",
      "           -2.6908e-02, -2.2695e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0655e-01,  2.0142e-01, -2.4825e-03,  ..., -2.8279e-01,\n",
      "           -3.6953e-01, -1.4849e-01],\n",
      "          [-3.8290e-01,  3.0664e-02, -8.7813e-01,  ...,  1.8302e-01,\n",
      "           -7.4977e-01, -8.3532e-01],\n",
      "          [-1.4643e-01, -8.8261e-01,  3.6478e-01,  ..., -5.8976e-01,\n",
      "            5.4396e-01, -4.8398e-01],\n",
      "          ...,\n",
      "          [-3.9536e-01,  3.2327e-02, -5.2808e-01,  ..., -1.9586e-01,\n",
      "           -2.7643e-01, -6.4038e-01],\n",
      "          [ 6.5533e-02, -5.0690e-01,  7.9890e-01,  ..., -6.6282e-01,\n",
      "            4.9629e-01, -6.5537e-01],\n",
      "          [-1.4312e-01, -9.6786e-02, -2.0981e-01,  ..., -1.0821e-01,\n",
      "           -1.7078e-01, -2.4290e-01]],\n",
      "\n",
      "         [[ 4.7853e-01,  7.8670e-02,  3.5708e-01,  ...,  1.9413e-01,\n",
      "            3.5219e-01,  2.6458e-02],\n",
      "          [-3.8540e-01, -6.1770e-01, -3.3725e-01,  ..., -7.2915e-01,\n",
      "            1.4183e-01, -2.8876e-01],\n",
      "          [ 3.7914e-01,  4.2969e-01,  7.9751e-01,  ...,  1.2307e-01,\n",
      "            3.9815e-01,  1.1100e-01],\n",
      "          ...,\n",
      "          [-3.6145e-01, -5.3153e-01,  2.8994e-01,  ..., -1.3722e-01,\n",
      "            9.1531e-02, -4.5124e-01],\n",
      "          [ 1.2123e-01,  1.3441e-01,  4.4040e-01,  ...,  3.8173e-01,\n",
      "            3.0886e-01,  3.0019e-01],\n",
      "          [-2.2381e-01, -5.4903e-01, -3.7874e-02,  ..., -7.3573e-01,\n",
      "           -1.7704e-01, -6.2537e-01]],\n",
      "\n",
      "         [[-5.1992e-02, -6.5610e-01,  1.0212e-02,  ..., -1.6282e-01,\n",
      "            3.5836e-01, -3.1420e-01],\n",
      "          [-3.6717e-01,  6.2067e-01,  1.9601e-01,  ..., -9.7530e-02,\n",
      "           -4.0155e-01, -5.6027e-01],\n",
      "          [ 2.6614e-01, -3.7966e-01,  4.5219e-01,  ...,  3.0603e-01,\n",
      "           -5.3726e-01, -6.6971e-01],\n",
      "          ...,\n",
      "          [-3.3831e-01,  6.9919e-01,  2.2198e-01,  ...,  1.8192e-01,\n",
      "            9.1267e-03, -3.4288e-01],\n",
      "          [ 2.4014e-01, -6.9866e-02, -2.8222e-02,  ..., -3.1279e-01,\n",
      "            2.3678e-01, -5.1043e-01],\n",
      "          [-5.8026e-02, -5.7649e-02,  1.8402e-01,  ...,  2.2413e-01,\n",
      "            2.5421e-01, -1.7053e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.4485e-01,  2.3377e-01, -1.8471e-01,  ..., -1.2943e-01,\n",
      "           -3.5100e-01, -1.9618e-01],\n",
      "          [-4.5740e-01, -4.0517e-01, -7.5496e-01,  ...,  3.9884e-01,\n",
      "           -7.1235e-01, -7.5471e-01],\n",
      "          [-2.2519e-01, -8.8419e-01,  6.1800e-01,  ..., -5.9033e-01,\n",
      "            1.3293e-01, -4.7458e-01],\n",
      "          ...,\n",
      "          [-3.7658e-01, -3.0847e-01, -2.4534e-01,  ..., -2.4626e-01,\n",
      "           -2.4029e-01, -5.4936e-01],\n",
      "          [ 7.1235e-02, -4.5097e-01,  5.8793e-01,  ..., -4.4679e-01,\n",
      "            6.6287e-01, -5.0789e-01],\n",
      "          [-6.3235e-02, -5.8851e-02, -1.3847e-01,  ...,  1.0940e-02,\n",
      "           -6.2119e-01, -2.4367e-02]],\n",
      "\n",
      "         [[ 4.1701e-01,  5.5896e-02,  4.3396e-01,  ...,  7.9079e-02,\n",
      "            3.9836e-01, -7.8849e-03],\n",
      "          [-4.7349e-01, -5.2667e-01, -4.9050e-01,  ..., -6.9496e-01,\n",
      "           -3.5442e-01, -2.7600e-01],\n",
      "          [ 3.9533e-01,  1.8307e-01,  6.1677e-02,  ...,  2.1582e-01,\n",
      "            3.4266e-01,  2.0253e-01],\n",
      "          ...,\n",
      "          [-2.7415e-01, -3.9596e-01,  6.9115e-01,  ..., -3.6868e-01,\n",
      "            7.7378e-02, -2.8907e-01],\n",
      "          [ 7.2718e-02,  1.6526e-01,  5.6789e-01,  ...,  5.4986e-01,\n",
      "            8.8544e-02,  3.7723e-01],\n",
      "          [-1.3430e-01, -6.7753e-01,  2.0984e-01,  ..., -7.7082e-01,\n",
      "            7.3093e-02, -6.9630e-01]],\n",
      "\n",
      "         [[-1.5885e-02, -5.0247e-01,  1.6968e-01,  ...,  1.8594e-01,\n",
      "            1.4191e-01, -2.7570e-01],\n",
      "          [-3.0869e-01,  2.3917e-01,  3.8942e-01,  ..., -7.6902e-02,\n",
      "            1.4328e-01, -7.2432e-01],\n",
      "          [-2.1552e-04, -3.3179e-02,  4.4929e-01,  ..., -2.5164e-02,\n",
      "           -1.2331e-01, -6.7719e-01],\n",
      "          ...,\n",
      "          [-3.6063e-01,  6.8928e-01,  4.0659e-01,  ...,  4.2258e-01,\n",
      "           -4.7888e-01, -4.7668e-02],\n",
      "          [ 1.6475e-01, -3.2755e-01, -2.8059e-02,  ..., -4.1661e-01,\n",
      "            5.3194e-01, -5.7957e-01],\n",
      "          [ 3.4913e-02, -9.6891e-02,  6.0410e-02,  ...,  1.5892e-01,\n",
      "            2.9341e-01, -1.9279e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5226e-01,  1.6010e-01, -1.2925e-01,  ..., -3.6000e-01,\n",
      "           -3.4060e-01, -3.4861e-01],\n",
      "          [-5.9547e-01, -3.1660e-01, -8.7417e-01,  ...,  2.9680e-01,\n",
      "           -6.3767e-01, -6.7114e-01],\n",
      "          [-3.1301e-01, -8.6369e-01,  6.4621e-01,  ..., -6.5494e-01,\n",
      "            5.1880e-01, -4.9882e-01],\n",
      "          ...,\n",
      "          [-4.1295e-01, -2.2617e-01, -4.0442e-01,  ..., -4.9730e-01,\n",
      "           -5.3599e-01, -6.9750e-01],\n",
      "          [-5.5301e-02, -2.0406e-01,  7.4007e-01,  ..., -4.2936e-01,\n",
      "            4.2924e-01, -6.5870e-01],\n",
      "          [-1.3934e-01,  4.8698e-03, -7.9209e-02,  ...,  3.1999e-03,\n",
      "           -4.8923e-01, -2.4106e-01]],\n",
      "\n",
      "         [[ 3.1696e-01, -1.1639e-01,  4.3964e-01,  ...,  2.8024e-01,\n",
      "            5.6349e-01,  7.1422e-02],\n",
      "          [-2.0323e-01, -7.7603e-01, -2.2830e-01,  ..., -4.8873e-01,\n",
      "           -1.5102e-01, -2.2433e-01],\n",
      "          [ 4.8168e-01,  7.9308e-02,  5.4822e-01,  ...,  1.6537e-01,\n",
      "            4.4274e-01,  2.7183e-01],\n",
      "          ...,\n",
      "          [-3.2519e-01, -4.2589e-01,  3.8654e-01,  ..., -5.7671e-01,\n",
      "            1.8211e-02, -2.0813e-01],\n",
      "          [ 2.5845e-01, -6.7653e-02,  3.4946e-01,  ...,  1.0032e-01,\n",
      "            3.7467e-01,  1.4757e-02],\n",
      "          [-3.7258e-02, -6.2958e-01,  9.3034e-02,  ..., -7.4360e-01,\n",
      "           -1.1064e-01, -5.5848e-01]],\n",
      "\n",
      "         [[ 1.4572e-02, -6.2448e-01,  2.1452e-01,  ..., -1.4625e-01,\n",
      "            1.6070e-01, -2.9055e-01],\n",
      "          [-3.3045e-02,  1.8559e-01,  5.7001e-02,  ..., -3.2188e-01,\n",
      "           -2.8428e-01, -5.9928e-01],\n",
      "          [-1.0484e-01,  3.7987e-02,  2.2400e-01,  ...,  2.6984e-02,\n",
      "           -5.8590e-01, -5.2657e-01],\n",
      "          ...,\n",
      "          [-3.5101e-01,  7.1113e-01, -3.6151e-01,  ...,  5.3989e-01,\n",
      "           -4.5615e-01, -1.9847e-01],\n",
      "          [ 4.8327e-01, -3.5540e-02, -1.8788e-01,  ..., -2.9775e-01,\n",
      "            2.2744e-01, -4.6958e-01],\n",
      "          [ 1.6013e-02, -5.4894e-02,  2.5870e-01,  ...,  2.7207e-01,\n",
      "            2.5228e-01, -2.5949e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5257e-01,  9.0846e-02, -1.6352e-01,  ..., -3.9024e-01,\n",
      "           -1.7165e-01, -1.9664e-01],\n",
      "          [-5.9032e-01, -3.7699e-01, -7.7172e-01,  ..., -2.7768e-02,\n",
      "           -5.9241e-01, -7.9758e-01],\n",
      "          [-1.4089e-02, -9.4107e-01,  6.7923e-01,  ..., -6.4390e-02,\n",
      "            3.0539e-01, -3.6469e-01],\n",
      "          ...,\n",
      "          [-3.8419e-01, -1.8211e-01, -1.6525e-01,  ..., -3.0622e-01,\n",
      "           -3.6555e-01, -5.4948e-01],\n",
      "          [-4.3817e-02, -2.9199e-01,  7.7562e-01,  ..., -5.8298e-01,\n",
      "            5.0446e-01, -5.1737e-01],\n",
      "          [ 8.1025e-02, -1.3568e-01, -1.6921e-01,  ..., -3.3538e-02,\n",
      "           -3.8218e-01, -2.3685e-01]],\n",
      "\n",
      "         [[ 3.0321e-01,  2.7176e-01,  3.9590e-01,  ...,  7.2697e-02,\n",
      "            4.0664e-01, -9.4719e-02],\n",
      "          [-2.9256e-01, -7.7479e-01, -2.5381e-01,  ..., -4.5914e-01,\n",
      "            1.2102e-01, -3.8998e-01],\n",
      "          [ 3.2487e-01,  3.8430e-01,  1.8544e-01,  ...,  2.0389e-01,\n",
      "            7.0104e-01, -1.4965e-01],\n",
      "          ...,\n",
      "          [-2.1603e-01, -9.1925e-02,  5.8606e-01,  ..., -2.7474e-01,\n",
      "            2.1519e-02, -3.5571e-01],\n",
      "          [ 3.4290e-01,  5.2745e-02,  6.3622e-01,  ...,  5.5868e-01,\n",
      "            6.2665e-02,  8.9872e-02],\n",
      "          [-2.5254e-01, -5.9528e-01, -1.3583e-01,  ..., -5.7590e-01,\n",
      "           -9.2840e-02, -6.3193e-01]],\n",
      "\n",
      "         [[-6.4953e-02, -5.9057e-01,  1.1348e-01,  ..., -2.6708e-01,\n",
      "            2.8112e-01, -2.8094e-01],\n",
      "          [-4.6627e-01,  1.1967e-01,  4.0171e-02,  ..., -2.3633e-01,\n",
      "           -9.3598e-02, -6.5060e-01],\n",
      "          [ 2.4233e-02,  6.8221e-02,  5.6014e-01,  ..., -2.6847e-01,\n",
      "           -3.6003e-01, -6.4248e-01],\n",
      "          ...,\n",
      "          [-2.5007e-01,  7.6036e-01,  6.4278e-03,  ...,  5.5579e-01,\n",
      "           -1.7885e-01, -3.5940e-01],\n",
      "          [ 1.8029e-01, -7.2341e-01,  2.3396e-01,  ..., -3.8301e-01,\n",
      "            2.3919e-01, -5.2474e-01],\n",
      "          [-4.5358e-02,  3.0253e-01,  4.3323e-01,  ..., -5.0263e-02,\n",
      "            1.4067e-01, -6.1202e-02]]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'byte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Trainer(\n\u001b[1;32m      2\u001b[0m     n_ckpt_steps\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     n_log_steps\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     g_lr\u001b[39m=\u001b[39;49m\u001b[39m0.0002\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     d_lr\u001b[39m=\u001b[39;49m\u001b[39m0.0004\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     noise_d\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     emb_d\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     output_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     flush_prev_logs\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     12\u001b[0m )\u001b[39m.\u001b[39;49mrun()\n",
      "Cell \u001b[0;32mIn[15], line 77\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m---> 77\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_iter(e)\n\u001b[1;32m     78\u001b[0m     \u001b[39m# Save final model\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     torch\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator\u001b[39m.\u001b[39mstate_dict(), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dir\u001b[39m}\u001b[39;00m\u001b[39m/generator.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 113\u001b[0m, in \u001b[0;36mTrainer.train_iter\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_image(\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator(noise)[\u001b[39m0\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_step\u001b[39m}\u001b[39;00m\u001b[39m_fake_image.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39m# Compute inception score\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minception\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerator(noise))\n\u001b[1;32m    114\u001b[0m \u001b[39m# Compute FID\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfid\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator(noise), \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Programming/DeepLearning/GANs/venv/lib/python3.8/site-packages/torchmetrics/metric.py:390\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    391\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    392\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/Desktop/Programming/DeepLearning/GANs/venv/lib/python3.8/site-packages/torchmetrics/image/inception.py:138\u001b[0m, in \u001b[0;36mInceptionScore.update\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, imgs: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Update the state with extracted features.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     imgs \u001b[39m=\u001b[39m (imgs \u001b[39m*\u001b[39;49m \u001b[39m255\u001b[39;49m)\u001b[39m.\u001b[39;49mbyte() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize \u001b[39melse\u001b[39;00m imgs\n\u001b[1;32m    139\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minception(imgs)\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mappend(features)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'byte'"
     ]
    }
   ],
   "source": [
    "Trainer(\n",
    "    n_ckpt_steps=1000,\n",
    "    n_log_steps=1000,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    g_lr=0.0002,\n",
    "    d_lr=0.0004,\n",
    "    noise_d=100,\n",
    "    emb_d=512,\n",
    "    output_size=64,\n",
    "    flush_prev_logs=False,\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceEngine:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.generator = Generator()\n",
    "        self.generator.load_state_dict(torch.load(model_path)[\"generator\"])\n",
    "\n",
    "    def generate(self, output_path: str = \"results/out.png\"):\n",
    "        noise = torch.randn((1, 100, 1, 1))\n",
    "        image, _, _ = self.generator(noise)\n",
    "        # Make directory to save to\n",
    "\n",
    "        torchvision.utils.save_image(image, output_path, normalize=True, range=(-1, 1))\n",
    "        print(f\"Generated image saved at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = InferenceEngine(\n",
    "    \"/home/j/Desktop/Programming/DeepLearning/GANs/results/checkpoints/505000.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved at results/out.png\n"
     ]
    }
   ],
   "source": [
    "inference.generate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cd50f146da535ab3830ed5f78683553ef57acd3032c46b9f95757dd92f9c813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
